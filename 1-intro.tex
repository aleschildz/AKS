Una de las preguntas más fundamentales de la matemática, estudiada desde la Antigüedad, es cómo decidir rápidamente si un entero positivo es primo o compuesto. Dicho problema no solo tiene una enorme importancia teórica, sino que también es crucial en criptografía.

Dado un entero positivo $n$, un algoritmo sencillo para decidir primalidad sería revisar si existe algún divisor de $n$ que sea mayor que $1$ y menor que $n$. Esto requerirá del orden de $n$ divisiones. No es difícil convencerse de que, en realidad, solo es necesario hacer esa revisión hasta $\sqrt{n}$, pues cualquier número compuesto debe tener un divisor en ese rango. Esto reduce el número de divisiones del algoritmo al orden de $\sqrt{n}$. Sin embargo, esto sigue siendo demasiado lento. Por ejemplo, decidir si un número de $100$ dígitos es primo usando ese algoritmo podría requerir hasta $\sqrt{10^{100}} = 10^{50}$ divisiones, lo que excede por mucho la capacidad de un computador moderno. Puesto que los protocolos criptográficos actuales trabajan con números de cientos de dígitos, dicho algoritmo no es útil. Cuando decimos que nos gustaría contar con un algoritmo rápido, nos referimos a que el número de divisiones debiese crecer de manera polinomial respecto al número de dígitos de la entrada. En otras palabras, necesitamos un algoritmo cuya complejidad en el peor de los casos sea un polinomio respecto a $\log(n)$. Por supuesto, la complejidad asintótica $\sqrt{n}$ que acabamos de discutir no cumple esa condición.

En 1976, Gary L. Miller \cite{MR480295} descubrió un algoritmo que correría en tiempo $O\left(\log^4(n) \right)$, pero asumiendo la hipótesis extendida de Riemann: una conjetura de la teoría de números que hasta el día de hoy no ha sido demostrada. Posteriormente, en 1980, Michael O. Rabin \cite{MR566880} presentó una modificación al test de Miller que eliminaba ese supuesto no probado, pero con el costo de volverlo un algoritmo probabilista. Este nuevo test podía cometer falsos positivos de primalidad, en el sentido de que, al recibir como entrada un número compuesto, había una probabilidad pequeña de que lo identificara incorrectamente como primo. A pesar de este problema, dicho algoritmo, conocido como el test de Miller-Rabin, es ampliamente utilizado hasta el día de hoy debido a su rapidez y a su baja probabilidad de error. Durante el siglo pasado se desarrollaron varios otros test de primalidad, como el propuesto por Robert M. Solovay y Volker Strassen en 1977 \cite{MR429721}. Sin embargo, se mantenía abierta la pregunta de si existía un test de primalidad determinista que corriera en tiempo polinomial y cuya correctitud no dependiera de alguna conjetura no demostrada.
Finalmente, en el año 2004, Manindra Agrawal, Neeraj Kayal y Nitin Saxena \cite{AKS04} dieron una respuesta positiva a dicha pregunta, presentando un algoritmo determinista de tiempo polinomial basado en resultados de teorí­a de números y álgebra abstracta, que pasaría a ser conocido como el test de primalidad AKS.

Si bien el algoritmo AKS es sencillo de programar, las razones por las que funciona son profundas. La demostración de correctitud presentada en \cite{AKS04} puede resultar inaccesibles para quienes no están familiarizados con las técnicas de álgebra abstracta utilizadas. Por esto, el objetivo del presente trabajo es dar una explicación ampliada y autocontenida del algoritmo, partiendo desde las definiciones algebraicas más básicas.
